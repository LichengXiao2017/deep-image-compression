# Run this script at directory deep-image-compression/, with command:
# '''bin/model_inference_compress_my_approach'''

# Inference my approach model and compress image
# Running time will be around 9 seconds per image on GTX 1070, can be greatly
# shortened by pre-loading model checkpoint (actual inference time should be
# less than 1 second)

TEST_DATA_PATH=/path/to/test/image.png
MODEL_PATH="./model/my_approach"
NUM_FILTERS=192

python3 my_approach.py \
--num_filters ${NUM_FILTERS} \
--checkpoint_dir ${MODEL_PATH} \
compress \
--input_file ${TEST_DATA_PATH}
